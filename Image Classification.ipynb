{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, Activation, Dropout, Dense, Flatten, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "DATADIR = \"C:/Users/User/Desktop/ML/Clothes\"\n",
    "CATEGORIES = [\"Notags\", \"Tags\"]\n",
    "IMG_SIZE = 256\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # notags and tags categories\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to notags and tags\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=nptag 1=tag\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per notags and tags\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize image size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # pass errors\n",
    "                pass\n",
    "\n",
    "create_training_data() \n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#Shuffle data\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "#Split to features and labels\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "y = np.array(y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize RGB from (0,255) to (0,1)\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store features array on disk\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "#Store labels array on disk\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load features and labels without a need to extract and clean data\n",
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "pickle_in = open(\"y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name for tensorboard logs My CNN 80-83% valaccuracy\n",
    "NAME = \"Tags-notags-clothes-CNN-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "IMG_SIZE = 256\n",
    "# Model Architecture \n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model compilation\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=RMSprop(lr=0.001),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with 15 epochs and 20% validation split. Logs of loss and accuracy are sent to tensorboard\n",
    "epochs = 12\n",
    "model.fit(X, y, batch_size=32, validation_split=0.2, epochs=epochs,verbose=1, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Model\n",
    "model.save('5Conv-Tag-CNN.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Load Model\n",
    "model = tf.keras.models.load_model('5Conv-Tag-CNN.model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = [\"Notag\", \"Tag\"]  # will use this to convert prediction num to string value\n",
    "\n",
    "notags_test_filepath = \"C:/Users/User/Desktop/ML/Clothes/Notags_test\"\n",
    "tags_test_filepath = \"C:/Users/User/Desktop/ML/Clothes/Tags_test\"\n",
    "\n",
    "def prepare_testimages(filepath):\n",
    "    IMG_SIZE = 256\n",
    "    img_array = cv2.imread(filepath)  # read in the image\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)  # return the image with shaping that TF wants.\n",
    "\n",
    "tag_count_right = 0        \n",
    "tagcount = len(os.listdir(tags_test_filepath))\n",
    "#Tags_test\n",
    "for img in os.listdir(tags_test_filepath):\n",
    "    prediction = model.predict([prepare_testimages(os.path.join(tags_test_filepath,img))])\n",
    "    if int(prediction[0][0]) == 1:\n",
    "        tag_count_right += 1\n",
    "\n",
    "notag_count_right = 0        \n",
    "notagcount = len(os.listdir(notags_test_filepath))\n",
    "\n",
    "#Notags_test\n",
    "for img in os.listdir(notags_test_filepath):\n",
    "    prediction = model.predict([prepare_testimages(os.path.join(notags_test_filepath,img))])\n",
    "    if int(prediction[0][0]) == 0:\n",
    "        notag_count_right += 1\n",
    "        \n",
    "print(\"tag_accuracy:{0}, notag_accuracy:{1}\".format(tag_count_right/tagcount, notag_count_right/notagcount))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = [\"Notag\", \"Tag\"]  # will use this to convert prediction num to string value\n",
    "\n",
    "notags_test_filepath = \"C:/Users/User/Desktop/ML/Clothes/Notags_test\"\n",
    "tags_test_filepath = \"C:/Users/User/Desktop/ML/Clothes/Tags_test\"\n",
    "\n",
    "def prepare_testimages(filepath):\n",
    "    IMG_SIZE = 256\n",
    "    img_array = cv2.imread(filepath)  # read in the image\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)  # return the image with shaping that TF wants.\n",
    "\n",
    "tag_count_right = 0        \n",
    "tagcount = len(os.listdir(tags_test_filepath))\n",
    "#Tags_test\n",
    "for img in os.listdir(tags_test_filepath):\n",
    "    prediction = model.predict([prepare_testimages(os.path.join(tags_test_filepath,img))])\n",
    "    if int(prediction[0][0]) == 1:\n",
    "        tag_count_right += 1\n",
    "\n",
    "notag_count_right = 0        \n",
    "notagcount = len(os.listdir(notags_test_filepath))\n",
    "\n",
    "#Notags_test\n",
    "for img in os.listdir(notags_test_filepath):\n",
    "    prediction = model.predict([prepare_testimages(os.path.join(notags_test_filepath,img))])\n",
    "    if int(prediction[0][0]) == 0:\n",
    "        notag_count_right += 1\n",
    "        \n",
    "print(\"tag_accuracy:{0}, notag_accuracy:{1}\".format(tag_count_right/tagcount, notag_count_right/notagcount))        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}